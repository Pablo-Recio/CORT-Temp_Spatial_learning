---
docx: 
bibliography: "./bib/refs.bib"
csl: "./bib/biology-letters.csl"
reference-doc: "./bib/tmpl.docx"
execute:
  echo: false
  error: false
  cache: false
  warning: false
link-citations: true
crossref:  
  fig-title: Fig    # (default is "Figure")
  title-delim: —     # (default is ":")
  fig-prefix: Fig.   # (default is "Figure")
  tbl-prefix: Table  # (default is "Table")
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
pacman::p_load(tidyverse, flextable, emmeans, DHARMa, brms, here, ggplot2, lme4, zoo, lmerTest, broom, tidybayes, ggh4x, cowplot, fitdistrplus, MASS, goftest, forcats, nortest, fitdistrplus, ggh4x, PupillometryR, png, grid, remotes, ggthemes, bayestestR, HDInterval, DiagrammeR, magick)
```

```{r, data_processing}
#| label: data_processing
# The result will be the final df with the data for the analysis. To do so, we first estimate the learning slope (choice and errors) for each individual and then merge the data with the mitochondrial data, extracted using the script in extract.R and extraction_finc.R (see R folder). The final df will be saved in (here("output/databases_clean/data_complete.csv") 
refit <- FALSE
source(here("R", "data_process.R"))
```

```{r, data_metrics}
#| label: data_metrics
# Using the raw learning database, I calculate here some basic metrics mentioned later in the Methdos (see below).
data <- read.csv(here("./data/Spatial_learn.csv"))
#
# Total number of clutches
total_clutches <- data %>% 
  distinct(clutch) %>% 
  count() %>% 
  pull(n)
# Calculate total number of individuals
total_individuals <- data %>% 
  distinct(lizard_id) %>% 
  count() %>% 
  pull(n)
# Calculate number of individuals per clutch
individuals_per_clutch <- data %>%
  distinct(lizard_id, clutch) %>%
  group_by(clutch) %>%
  summarize(individual_count = n())
```


## Introduction
**Corticosterone is the major GC produced by
adrenal steroidogenic cells in reptiles, and an increase in
its plasma concentration is a frequent indicator of stress
(Anderson et al. 2014 General and Comparative Endocrinology). In nature,
GCs in the developing embryos seem to be largely of
maternal origin (Uller et al. 2009, The Journal of Experimental Biology) and are probably transferred to the growing oocytes through vitellogenesis (Elf et al.,
2002, 2003 General and Comparative Endocrinology (both)).**

Mechanistically, a change in body size requires
a change in cell number and/or cell size, and there is evidence that
body size and cell size undergo coordinated evolutionary (Arendt,
2007; Starostová et al., 2005; Stevenson et al., 1995) or
phenotypically plastic changes (Arendt, 2007; Czarnoleski et al.,
2013; Hessen et al., 2013).

## Methods  

#### Animal husbandry  
*Breeding colony* - We tested _L. delicata_ coming from a breeding colony established in the laboratory since 2019. This colony consisted of 270 adults housed in plastic containers (41.5 L x 30.5 W x 21 H cm) with six lizards (two males and four females) per enclosure. Enclosures were provided with nonstick matting, shelter, and several small water dishes. Water was given daily, and the lizards were fed approx. 40 mid-size crickets (_Acheta domestica_) per enclosure three days a week. Crickets were dusted with calcium weekly and multivitamin and calcium biweekly. Room temperatures were set to 22-24 ºC, but we also provided the enclosures with a heat chord and a heat lamp following a 12 h light:12 h dark cycle keeping warm side of enclosures is usually at 34 ºC.

*Eggs collection and incubation* - Between mid-November 2023 and mid-January 2024, we provide females with a place to lay the eggs by placing a small box (12.5 L x 8.3 W x 5 H cm) with moist vermiculite in one side of the communal enclosures. These boxes were checked three days a week. After egg collection, we measured length and width with a digital caliper to the nearest 0.1 mm and weighted the eggs with a digital scale ± 0.001g error. Then eggs were treated with CORT or vehicle (see CORT and temperature manipulation below) and were placed in individual cups (80 mL) with moist vermiculite (12 parts water to 4 parts vermiculite). The cups were covered with cling wrap to retain moisture and left in two incubators at two different temperatures (see CORT and temperature manipulation below) until hatching.

*Hatchlings* - Incubators were checked three times a week for hatchlings. Lizards were measured and weighed immediately after hatching. Snout-vent length (SVL) and tail length (TL) were measured to the nearest millimeter, and weight was recorded using a digital scale with an accuracy of ± 0.001 g. Hatchlings were then placed in individual enclosures (18.7L x 13.2W x 6.3H cm) with nonstick matting and a small water dish. Watering, feeding, and temperature conditions were maintained as for adults (see above).      

#### CORT and Temperature manipulation
To test the interactive effects of CORT and incubation temperature, we manipulated CORT concentrations in eggs and incubated them under one of two temperature regimes (Cold - 23 ± 3 ºC or Hot - 28 ± 3 ºC) in a 2x2 factorial design (@fig). Eggs were assigned to one fo the two hormone treatments: CORT or Control. CORT-treated lizards were topically supplied with 5 µL of crystalline corticosterone (Sigma, Cat. No. C2505) dissolved in 100% ethanol at a final 10 pg CORT/mL concentration (CORT treatment), while Control lizards received an equal volume of 100% Ethanol (Control treatment). We selected doses based on previous studies where CORT treatment increased mean yolk CORT levels ~3.7x higher than control eggs [**ONDI'S PAPER**]. Then, eggs were incubated in one of the two previously mentioned temperature regimes. These temperatures are within the natural limits in _L. delicata_ [@cheetham2011embryonic].   
The number of eggs per clutch assigned to each hormone and temperature treatment was counterbalanced in a partial split-clutch design. At least one egg per clutch was assigned to each treatment, while in cluthces bigger than four the remaining eggs were randomly assigned to one of the treatments. When we found less than four eggs in a clutch, we assigned each egg randomly to one of the treatments.   

#### Learning  
The spatial learning task involved training lizards to navigate a 6-arm maze to reach an exit connected to a transport box that allowed us to return the lizards to their enclosure without further contact. The maze was constructed from white polylactic acid (PLA) and featured six arms extending from a hexagonal central starting point (see @fig).  

In each trial, the lizards were placed by hand in the center of maze and left to acclimate for two minutes  (see @fig). During acclimatation, the central are was surrounded by a yellow 3D-printed PLA device mounted on a pulley system. At the start of each trial, this device was lifted to startle the lizard. If the lizard did not immediately choose an arm, it was gently prodded with a brush at the end of the tail. Once the lizard made a choice, the brush was used to encourage movement but without guiding it towards any specific arm. If the lizard did not choose correctly after 20 errors — at which point it typically ceased responding — the lizard was gently guided to the correct arm.  

Extra-maze cues (but not intra-maze cues) were available to assist with navigation. This design aimed to assess the lizards' ability to learn spatial relationships based on external cues rather than relying on familiar objects within the maze. To avoid confounding effects from chemical cues, the maze was cleaned with 70% ethanol between trials. To control for visual cues related to the correct arm, the maze was rotated every three trials while maintaining the orientation of the correct arm and the maze's position within the room, which remained consistent for each individual.  

To control for potential side biases, the correct arm was randomly assigned to one of the six arms for each trial. We employed four different maze orientations (North-West, South-West, South, and South-East), and the number of lizards assigned to each orientation was counterbalanced across treatments.  

The task was repeated once daily for 40 consecutive days, and the number of mistakes made by each lizard was recorded. A mistake was defined as the lizard inserting its head into one of the incorrect arms. The primary measure of spatial learning was the total number of errors made before the lizard chose the correct arm.  

```{r, fig-Methods}
#| label: fig-Methods
#| fig.cap: "Panel **A** shows the experimental design of the study. On top, the treatments applied to the eggs. On the bottom the learning task and the brain region extracted together with the physiological analyses performed. In panel **B** the details and measurements of the spatial learning maze."

knitr::include_graphics("./Others/SPAL_METH.svg")

```

#### Brain extraction

#### Brain mitochondrial activity
Two months after the completion of the tests, we euthanises lizards usin an injectable anaesthetic followed by decapitation. We injected peritoneally 10 mg/kg of a 10 mg/mL alfaxan solution (**REF?**). After some minutes, we evaluated the lizards response by turning it upside down, and by testing the pinching relfex in the hand. Lizards were decapitated once they were not responsive.

**After decapitation, the head was opened and the brain dissected. We focused on two main regions of the brain, the olfactory bulbs and the optic tecta, as they are associated with lizards' chemical and visual perception, respectively (Wynecken, 2007).**

#### Statistical analyses  

We also considered individuals to be reinforced if the cricket was eaten after the test independently of whether their initial choice was correct or not.  
**As such, we run a total of different 8 models employing Bayesian multilevel models using the brm function from the brms package (@burkner2017brms) in Quarto (@Allaire_Quarto_2022). Each model consisted of four parallel chains of 3000 iterations, with a warm up interval of 1000 iterations.'Choice', i.e. whether the individual chose correct (1) or not (0) was used as the response variable. The fixed effects of the model included a triple interaction between: trial ('Associative trial' or 'Reversal trial') as a numeric variable, and hormone treatmet ('CORT' versus 'Control') and the temperature at which eggs were incubated ('Cold' versus 'Hot') as factors. For the random effects, we employed lizard identity as a random intercept, and as a random slope we included the variable trial ('Associative' or 'Reversal') within each level of lizard identity. We used the resulting posterior of these models to evaluate learning differences between treatments within and between species and colour assigned. More specifically, we calculated learning slopes by using the estimates of the trial variable per each level of the hormone-temperature interaction ('Treatments'); values bigger from zero were considered as evidence of learning, while those less or equal to zero not. We used the pmcmc method to test whether those slopes or the comparissons between 'Treatments' (e.g. slope for 'CORT-Cold' lizards minus 'CORT-Hot' lizards) were different from zero (two-tailed tests). We considered statistical significance if p-value < 0.05.**  

There are a total of  `r total_individuals`, and `r total_clutches` clutches in the database. The average number of individuals per clutch is `r mean(individuals_per_clutch$individual_count)`, with a minimum of `r min(individuals_per_clutch$individual_count)` individuals per clutch (`r sum(individuals_per_clutch$individual_count == min(individuals_per_clutch$individual_count))` clutches) and a maximum of `r max(individuals_per_clutch$individual_count)` (`r sum(individuals_per_clutch$individual_count == max(individuals_per_clutch$individual_count))` clutches). Clutches with only one individual do not contribute to the estimation of within-clutch variability. Including these clutches might lead to misleading variance estimates and convergence issues in the hierarchical model. Therefore, we initially fit the model without the clutch effect to obtain stable estimates at the individual level.

## Results

Originally, we started with 96 lizards, 48 per species and 12 per treatment per species. However, due to natural mortality (n = 11), no completion of the training stage (n = 1), or no motivation during the learning tasks (n = 3; see above), we ended up with a total of 81 lizards. Final sample sizes per treatment and species are disclosed on @tbl-data. 

```{r, models_mitochondrial}
#| label: models_mitochondrial
# Fitting the model and extraction of posteriors for both types of task and species using fit_m function (see func.r in R folder). The result everytime the function is used is a df with the posteriors of the model. The functions saves the model automatically in output/models; and when the parameter refit = FALSE then the posteriors are extracted from the model previously written instead of fitting the model again each time.
source(here("R", "func.R"))
# 
#
# Run models mitochondrial physiology 
var_m <- c("mit_density", "mit_potential", "ROS", "DNAdamage", "peroxidation")
for (p in var_m){ 
  if (p %in% c("mit_density", "mit_potential", "ROS", "DNAdamage")){
    formula <- paste0(p, "~ cort*temp + (1|clutch)")
  } else if (p == "peroxidation"){
    formula <- paste0(p, "~ cort*temp + age + (1|clutch)")
  } 
  pmodel_name <- paste0("m_def_", p)
  assign(pmodel_name, fit_m(df = clean_df,
                          cat = "def",
                          var = p,
                          formula = formula,
                          fam = gaussian(),
                          refit = FALSE),
        envir = .GlobalEnv)  # Assign to the global environment
} 
```

```{r, models_learning}
#| label: models_learning
#
formula_learn <- errors ~ day*cort*temp + (1 + day|lizard_id) + (1|clutch)
m_def_learn <- fit_m(df = learning_df,
                      cat = "def",
                      var = "learning",
                      formula = formula_learn,
                      fam = negbinomial(link = "log"),
                      refit = FALSE)
```

```{r, learning_results_names}
#| label: learning_results_names
# Rename some of the posteriors and make new estimates for the learning rate 
#
### Slopes
slope_ControlCold <- m_def_learn$b_day
slope_CORTCold <- m_def_learn$b_day + m_def_learn$`b_day:cortCORT`
slope_ControlHot <- m_def_learn$b_day + m_def_learn$`b_day:tempHot`
slope_CORTHot <- m_def_learn$b_day + m_def_learn$`b_day:cortCORT:tempHot` + m_def_learn$`b_day:cortCORT` + m_def_learn$`b_day:tempHot`
### Intercepts (for figure)
int_ControlCold <- m_def_learn$b_Intercept
int_CORTCold <- m_def_learn$b_Intercept + m_def_learn$`b_cortCORT`
int_ControlHot <- m_def_learn$b_Intercept + m_def_learn$`b_tempHot`
int_CORTHot <- m_def_learn$b_Intercept + m_def_learn$`b_cortCORT:tempHot` + m_def_learn$`b_cortCORT` + m_def_learn$`b_tempHot`
```

```{r, fig-learning}
#| label: fig-learning
#| fig.cap: "Learning results"
source(here("R", "func.R"))
#
#
####### A) Create df
# Slopes df (employed in fig-learning B)
slope_list <- list(`Control-Cold` = slope_ControlCold,
                 `CORT-Cold` = slope_CORTCold,
                 `Control-Hot` = slope_ControlHot,
                 `CORT-Hot` = slope_CORTHot)
data_fig_learning_slopes <- do.call(rbind, lapply(names(slope_list), function(x) {
  data.frame(treatment = x, slopes = slope_list[[x]])
}))
# Intercepst df (only for fig-learning A)
intercept_list <- list(`Control-Cold` = int_ControlCold,
                 `CORT-Cold` = int_CORTCold,
                 `Control-Hot` = int_ControlHot,
                 `CORT-Hot` = int_CORTHot)
data_fig_learning_intercepts <- do.call(rbind, lapply(names(intercept_list), function(x) {
  data.frame(treatment = x, intercepts = intercept_list[[x]])
})) %>% 
  group_by(treatment) %>%
  summarize(se_int = sd(intercepts)/sqrt(length(intercepts)),
            intercepts = mean(intercepts))
# df fig-learning A
data_fig_learning_slopesA <- data_fig_learning_slopes %>%
  group_by(treatment) %>%
  summarize(se_slope = sd(slopes)/sqrt(length(slopes)),
            slopes = mean(slopes),)
data_fig_learningB <- merge(data_fig_learning_slopesB, data_fig_learning_intercepts, by = "treatment")
treatment <- unique(data_fig_learningB$treatment)
fig_A_df <- data.frame()
for(t in treatment){ # Loop per treatment
  df <- data_fig_learningB %>%
    filter(treatment == t) %>%
    data.frame()
  # Variables selected
  m <- df$slopes
  u <- df$intercepts
  # Loop per treatment
  num_individuals <- length(u)
  for(x in 0:40){
    if (x == 0){
      standard <- df$se_int
    } else {
      standard <- df$se_slope
    }
    value <- exp(u + m * x)
    temp_df <- data.frame(trial = rep(x, length(value)),
                          treatment = rep(t, length(value)),
                          errors = value,
                          se = standard)
    fig_A_df <- rbind(fig_A_df, temp_df)
  }
}
# 
#### C) Plot the fig-learning A and fig-learning B separately 
fig_learningA <- plot_errors(fig_A_df)
fig_learningB <- plot_slopes(data_fig_learning_slopes)
#
#


errors_df <- data_spal %>%
  mutate(Treatment = paste(cort, temp, sep = "-")) %>%
    mutate(Treatment = factor(Treatment,
      levels = c("CORT-Cold", "Control-Cold", "CORT-Hot", "Control-Hot")
    )) %>%
  group_by(day, Treatment) %>%
  summarise(
    mean_errors = mean(errors, na.rm = TRUE),
    sd_errors = sd(errors, na.rm = TRUE)
  ) %>%
  ungroup() %>%
  data.frame()
fig_errors <- ggplot(learn_df, aes(x = Trial, y = Value, color = Treatment, fill = Treatment)) +
  geom_smooth(se = TRUE, linewidth = 1, alpha = 0.075) +
  scale_color_manual(values = c("CORT-Cold" = "#00008B", "Control-Cold" = "#68bde1", "CORT-Hot" = "#b50101", "Control-Hot" = "#fa927d")) +
  scale_fill_manual(values = c("CORT-Cold" = "darkblue", "Control-Cold" = "#68bde1", "CORT-Hot" = "#b50101", "Control-Hot" = "#fa927d")) +
  theme_classic() +
  labs(y = "Mean amount of errors made", x = "Trial") +
  theme(plot.margin = margin(5.5, 5.5, 5.5, 5.5, "mm")) +
  theme(
    axis.title = element_text(size = 12, family = "Times"),
    axis.text = element_text(size = 10, family = "Times"),
    legend.position = "none"
  )
## B.2) Make the the plot for the mean slope per treatment using the probability of choosing the correct feeder
fig_slope_errors <- plot_slopes("errors")
#
#
## B.3) Combine plots of probability and slopes to have the "choice" figure
fig_results_errors <- plot_grid(fig_errors, fig_slope_errors, nrow = 1) 
ggsave("./output/figures/fig_results_errors.png", plot=fig_results_errors, width = 25, height = 15, units = "cm", dpi = 600)
``` 


## Discussion

## References
<div id="refs"></div>

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

# Suplementary Material  


#### Results of the final models

Table S**13**. R^2^ values of the final models.
```{r, table_bayesR2}
#| label: table_bayesR2
#| tbl-cap: "BayesR2 values of the final models"
#
data_bayes <- data.frame(
  Model = character(0),
  Mean = numeric(0),
  Error = numeric(0),
  Q2_5 = numeric(0),
  Q97_5 = numeric(0)
)
models <- c("mean_mitodensity_def_OB",
            "mean_potential_def_OB",
            "mean_ros_def_OB",
            "mean_dnadamage_def_OB",
            "mean_peroxidation_def_OB",
            "t_D_def_Chemical",
            "mean_mitodensity_def_OT",
            "mean_potential_def_OT",
            "mean_ros_def_OT",
            "mean_dnadamage_def_OT",
            "mean_peroxidation_def_OT",
            "t_D_def_Visual")
#
for (m in models){
  mod <- readRDS(here("output/models/", paste0(m, ".rds")))
  bayes <- bayes_R2(mod)
  data_bayes <- rbind(data_bayes, data.frame(
    Model = m,
    Mean = format_dec(bayes[1], 3),
    Error = format_dec(bayes[2], 3),
    Q2_5 = format_dec(bayes[3], 3),
    Q97_5 = format_dec(bayes[4], 3)
  ))
}
#
bayes_table_df <- data_bayes %>%
  mutate(Region = gsub(".*_", "", Model)    # Extract everything after the last "_"
  ) %>%
  mutate(Model = factor(Model,
                        levels = c("mean_mitodensity_def_OB",
                                  "mean_potential_def_OB",
                                  "mean_ros_def_OB",
                                  "mean_dnadamage_def_OB",
                                  "mean_peroxidation_def_OB",
                                  "t_D_def_Chemical",
                                  "mean_mitodensity_def_OT",
                                  "mean_potential_def_OT",
                                  "mean_ros_def_OT",
                                  "mean_dnadamage_def_OT",
                                  "mean_peroxidation_def_OT",
                                  "t_D_def_Visual"),
                        labels = c("m_def_mean_mitodensity_OB" = "Mit density",
                                  "m_def_mean_potential_OB" = "Mit potential",
                                  "m_def_mean_ros_OB" = "ROS",
                                  "m_def_mean_dnadamage_OB" = "DNA damage",
                                  "m_def_mean_peroxidation_OB" = "Peroxidation",
                                  "m_def_t_D_Chemical" = "Detection lat",
                                  "m_def_mean_mitodensity_OT" = "Mit density",
                                  "m_def_mean_potential_OT" = "Mit potential",
                                  "m_def_mean_ros_OT" = "ROS",
                                  "m_def_mean_dnadamage_OT" = "DNA damage",
                                  "m_def_mean_peroxidation_OT" = "Peroxidation",
                                  "m_def_t_D_Visual" = "Detection lat")),
      Region = factor(Region, levels = c("OB", "Chemical", "OT", "Visual"),
                      labels = c("OB" = "Olfactory bulbs",
                                "Chemical" = "Chemical",
                                "OT" = "Optic tecta",
                                "Visual" = "Visual"))) %>%
  dplyr::select(Region, Model, Mean, Error, Q2_5, Q97_5) %>%
  arrange(Region, Model)
#
#
# Create the table
#
## Table format
set_flextable_defaults(
 font.family = "Times New Roman",
 font.size = 10)
#
bayes_table <- flextable(bayes_table_df) %>%
  set_header_labels(
    Region = "Region/Stimulus",
    Mean = "Mean",
    Error = "Error",
    Q2_5 = "2.5%",
    Q97_5 = "97.5%") %>%
  align(align = "center", j = c(3:5), part = "body") %>%
  align(align = "center", j = c(1:5), part = "header") %>%
  flextable::compose(i = c(2:5,8:11), j = 1, value = as_paragraph(""), part = "body") %>% # To remove some of the values in the first column
  flextable::hline(i = 6, part = "body") %>% 
  autofit()
#
bayes_table
```

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

Table S**14**. Results of the final models.
```{r, tbl-results_OB_table}
#| label: results_OB_table
#| tbl-cap: "Results of the models testing for Olfactory Bulbs."
#| tbl-name: "results_OB"
#| tbl-label: "results_OB"
source(here("R", "func.R"))
# 
# A) Refining the df summarizing the posteriors for OB/Chemical stimulus (post_OB)
post_OB_refined <- refine_post(post_OB) %>%
  arrange(Variable, Predictors)
#
# B) Create table
## Table format
set_flextable_defaults(
 font.family = "Times New Roman",
 font.size = 10)
#
OB_table <- flextable(post_OB_refined) %>%
  align(align = "center", j = c(3:5), part = "body") %>%
  align(align = "center", j = c(1:5), part = "header") %>%
  bold(~`PMCMC` < 0.05, j = c("PMCMC", "Estimate Mean", "95% CI", "Predictors"),
       bold = TRUE) %>%  # Bold when PMCMC is "<0.05"
  bold(~`PMCMC` <0.001, j = c("PMCMC", "Estimate Mean", "95% CI", "Predictors")) %>%  # Bold when PMCMC is "<0.001"
  flextable::compose(i = c(2:4,6:8,10:12,14:18,20:23,25:27), j = 1, value = as_paragraph(""), part = "body") %>% # To remove some of the values in the first column
  autofit()
#
OB_table
```

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

```{r, tbl-contrasts}
#| label: tbl-contrasts
#| tbl-cap: "Estimates of Associative learning slope for all the different treatments per each task, species and group. Mean shows the aritmetic mean of the estimates obtained from the posteriors of the model, and 95% CI indicates the 95% confidence interval of the mean. All p-values were obtained using pmcmc and test the hypothesis that the mean is equal to zero. In bold, those values that are significant (p-value <0.05)"
source(here("R", "func.R"))
#
############################## CREATING BIG DF FOR TABLE ##############################
# Building the vectors for titles of rows and columns
specie <- c("L. delicata", "L. guichenoti")
groups <- c("Red", "Blue")
test <- c("Associative", "Reversal")
treatments <- c("CORT-Cold", "Control-Cold", "CORT-Hot", "Control-Hot")
values <- c("Mean", "95% CI", "p-value")
# Building the vectors for estimated means, co.intervals(95%), and p-values for the slopes obtained from posteriors. p-values are obtained using pmcmc function (see func.R), assuming a two-tailed test that testes the hypothesis that the value (slopes in this case) is 0.
#First get estimates for both tasks
estimates_asso <- list(
  dar_CORTCold, dar_ControlCold, dar_CORTHot, dar_ControlHot, 
  dab_CORTCold, dab_ControlCold, dab_CORTHot, dab_ControlHot, 
  gar_CORTCold, gar_ControlCold, gar_CORTHot, gar_ControlHot, 
  gab_CORTCold, gab_ControlCold, gab_CORTHot, gab_ControlHot
)
#
estimates_rev <- list(
  drr_CORTCold, drr_ControlCold, drr_CORTHot, drr_ControlHot, 
  drb_CORTCold, drb_ControlCold, drb_CORTHot, drb_ControlHot, 
  grr_CORTCold, grr_ControlCold, grr_CORTHot, grr_ControlHot, 
  grb_CORTCold, grb_ControlCold, grb_CORTHot, grb_ControlHot
)
# Then get the mean, co.intervals(95%), and p-values
asso_mean <- format_dec(sapply(estimates_asso, mean), 3)
asso_interval_025 <- format_dec(sapply(estimates_asso, function(x) quantile(x,0.025)), 3)
asso_interval_975 <- format_dec(sapply(estimates_asso, function(x) quantile(x,0.975)), 3)
asso_intervals <- paste(asso_interval_025, asso_interval_975, sep = " , ")
asso_pvalue <- format_dec(sapply(estimates_asso, pmcmc), 3)
#
rev_mean <- format_dec(sapply(estimates_rev, mean), 3)
rev_interval_025 <- format_dec(sapply(estimates_rev, function(x) quantile(x,0.025)), 3)
rev_interval_975 <- format_dec(sapply(estimates_rev, function(x) quantile(x,0.975)), 3)
rev_intervals <- paste(rev_interval_025, rev_interval_975, sep = " , ")
rev_pvalue <- format_dec(sapply(estimates_rev, pmcmc), 3)
#
# Building the df for the associative
asso_df <- data.frame(
  Specie = rep(specie, each = length(groups) * length(treatments)),
  Group = rep(rep(groups, each = length(treatments)), times = length(specie)),
  Treatment = rep(rep(treatments, each = 1), times = length(groups) * length(specie)),
  Mean = rep(asso_mean, each = 1),
  CI = rep(asso_intervals, each = 1),
  PValue = rep(asso_pvalue, each = 1),
  Task = rep("Associative", length(asso_mean))
)
# Building the df for the reversal
rev_df <- data.frame(
  Specie = rep(specie, each = length(groups) * length(treatments)),
  Group = rep(rep(groups, each = length(treatments)), times = length(specie)),
  Treatment = rep(rep(treatments, each = 1), times = length(groups) * length(specie)),
  Mean = rep(rev_mean, each = 1),
  CI = rep(rev_intervals, each = 1),
  PValue = rep(rev_pvalue, each = 1),
  Task = rep("Reversal", length(rev_mean))
)
# Joining both dfs
table_data <- rbind(asso_df, rev_df)
table_data[, sapply(table_data, is.numeric)] <- lapply(table_data[, sapply(table_data, is.numeric)], function(x) format(x, scientific = FALSE))
#
############################## ADDING SAMPLE SIZE TO DF FOR TABLE ##############################
# Make n_list into a df
n_df <- as.data.frame(do.call(rbind, n_list)) %>%
  rename("n" = V1) %>%
  rownames_to_column("model") %>%
  separate(model, into = c("Specie", "Group", "cort", "temp"), sep = "_") %>%
  unite("Treatment", c("cort", "temp"), sep = "-") %>%
  mutate(Specie = factor(Specie,
                  labels = c(delicata = "L. delicata", guichenoti = "L. guichenoti")),
        Treatment = factor(Treatment,
                   levels = c("CORT-Cold", "Control-Cold", "CORT-Hot","Control-Hot")))
# Merge both dfs, put sample size together with the treatment, and organize the new df to make it look like the table
new_table_data <- merge(table_data, n_df) %>%
  rename('p-value' = 'PValue', '95% CI' = 'CI') %>% #Change the names of the columns for the table
  pivot_wider(names_from = Task, values_from = c(Mean, `95% CI`, `p-value`)) %>% # to split between Asociative and Reversal
  select(Specie, Group, Treatment, Mean_Associative, `95% CI_Associative`, `p-value_Associative`, Mean_Reversal, `95% CI_Reversal`, `p-value_Reversal`, n) %>% #To order the columns in the way I want for the table
  mutate(Specie = factor(Specie,
                  levels = c("L. delicata", "L. guichenoti")),
        Group = factor(Group,
                  levels = c("Red", "Blue")),
        Treatment = factor(Treatment, 
                  levels = c("CORT-Cold", "Control-Cold", "CORT-Hot", "Control-Hot")))%>%
  arrange(Specie, Group, Treatment) %>% # To arrange the rows the way I want
  unite("Treatment", c("Treatment", "n"), sep = " (n = ") %>%
  mutate(Treatment = paste0(Treatment, ")"))
write.csv(new_table_data, file= "./output/Checking/new_table_data.csv")
#
############################## MAKING THE TABLE ##############################
## Table format
set_flextable_defaults(
 font.family = "Times New Roman",
 fint.size = 10)
# Split the table_data df by task
real_table <- flextable(new_table_data) %>%
    bold(~ `p-value_Associative` < 0.05, ~ `p-value_Associative` + Mean_Associative + `95% CI_Associative`) %>%
    bold(~ `p-value_Reversal` < 0.05, ~ `p-value_Reversal` + Mean_Reversal + `95% CI_Reversal`) %>%
    set_table_properties(width = 1) %>%
    align(align="center", part="all") %>% 
    add_header_row(values = c("", "Associative task", "Reversal task"), colwidths = c(3, 3, 3)) %>%
    set_header_labels(Mean_Associative = "Mean",
                      `95% CI_Associative` = "95% CI",
                      `p-value_Associative` = "p-value",
                      Mean_Reversal = "Mean",
                      `95% CI_Reversal` = "95% CI",
                      `p-value_Reversal` = "p-value") %>%
    italic(j = 1, italic = TRUE, part = "body") %>% # To have names od species in italics
    flextable::compose(i = c(2:8,10:16), j = 1, value = as_paragraph(""), part = "body") %>% # To remove some of the values in the first column
    flextable::compose(i = c(2:4,6:8,10:12,14:16), j = 2, value = as_paragraph(""), part = "body") %>% # To remove some of the values in the second column
    hline(i = c(4,12), j = c(2:9), part = "body") %>% # To make some horizontal lines
    hline(i = c(8), j = c(1:9), part = "body") %>% # To make some horizontal lines
    vline(i = (1:16), j = c(3,6), part = "body") %>% # To make some vertical lines on body
    vline(j=c(3,6), part = "header") %>% # To make some vertical lines on header
    autofit() 
real_table
```

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```


#### Results of preliminary models  

```{r, models_preliminary}
#| label: models_preliminary
# Fitting preliminary models to see if sex and age are relevant for our models
source(here("R", "func.R"))
#
#
var_m <- c("mit_density", "mit_potential", "ROS", "DNAdamage", "peroxidation")
formula_list_ <- list()
for (p in var_m){
  formula_list_[[p]] <- paste0(p, "~ cort*temp + age + sex + (1|clutch)")
  pmodel_name <- paste0("m_prel_", p)
  assign(pmodel_name, fit_m(df = clean_df,
                             cat = "prel",
                             var = p,
                             formula = formula_list_[[p]],
                             fam = gaussian(),
                             refit = FALSE),
          envir = .GlobalEnv)  # Assign to the global environment
}
#
#
# Run model learning including the effect of sex and interaction
formula_learn <- errors ~ day*cort*temp + sex + age + (1 + day|lizard_id) + (1|clutch)
m_prel_learn <- fit_m(df = learning_df,
                      cat = "prel",
                      var = "learning",
                      formula = formula_learn,
                      fam = negbinomial(link = "log"),
                      refit = FALSE)
```

Table S1. Preliminary results of the models testing for Mitochondrial Density.

```{r, results_preliminary_mitdensity}
#| tbl-cap: "Preliminary results of the models testing for Mitochondrial Density"
#| label: results_preliminary_mitdensity
#
sum_mitdensity_prel <- m_prel_mit_density %>%
  dplyr::select(starts_with("b_")) %>%  # Removes random effect terms
  summarise_draws()  %>%
  mutate(across(where(is.numeric), ~ as.numeric(format_dec(.x, 3))))
#
flextable(sum_mitdensity_prel)
```

Model formula: mit_density ~ cort * temp + age + sex + (1|clutch).
Model convergence was checked through rhat and ess_bulk values. Summary indicates no effect of sex or age, so they were discarded from the final models.

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

Table S2.  Preliminary results of the models testing for Mitochondrial Potential.
```{r, results_preliminary_potential}
#| tbl-cap: "Preliminary results of the models testing for Mitochondrial Potential"
#| label: results_preliminary_potential
#
sum_potential_prel <- m_prel_mit_potential %>%
  dplyr::select(starts_with("b_")) %>%  # Removes random effect terms
  summarise_draws() %>%
  mutate(across(where(is.numeric), ~ as.numeric(format_dec(.x, 3))))
#
flextable(sum_potential_prel)
```

Model formula: mit_potential ~ cort * temp + age + sex + (1|clutch).
Model convergence was checked through rhat and ess_bulk values. Summary indicates no effect of sex or age, so they were discarded from the final models.

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

Table S3. Preliminary results of the models testing for ROS.
```{r, results_preliminary_ros}
#| tbl-cap: "Preliminary results of the models testing for ROS"
#| label: results_preliminary_ros
#
sum_m_ros_prel <- m_prel_ROS %>%
  dplyr::select(starts_with("b_")) %>%  # Removes random effect terms
  summarise_draws() %>%
  mutate(across(where(is.numeric), ~ as.numeric(format_dec(.x, 3))))
#
flextable(sum_m_ros_prel)
```

Model formula: ROS ~ cort * temp + age + sex + (1|clutch).
Model convergence was checked through rhat and ess_bulk values. Summary indicates no effect of sex or age, so they were discarded from the final models.

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

Table S4. Preliminary results of the models testing for DNA damage.
```{r, results_preliminary_dnadamage}
#| tbl-cap: "Preliminary results of the models testing for DNA damage"
#| label: results_preliminary_dnadamage
#
sum_m_dnadamage_prel <- m_prel_DNAdamage %>%
  dplyr::select(starts_with("b_")) %>%  # Removes random effect terms
  summarise_draws() %>%
  mutate(across(where(is.numeric), ~ as.numeric(format_dec(.x, 3))))
#
flextable(sum_m_dnadamage_prel)
```

Model formula: DNAdamage ~ cort * temp + age + sex + (1|clutch).
Model convergence was checked through rhat and ess_bulk values. Summary indicates no effect of sex or age, so they were discarded from the final models.

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

Table S5. Preliminary results of the models testing for lipid peroxidation.
```{r, results_preliminary_peroxidation}
#| tbl-cap: "Preliminary results of the models testing for lipid peroxidation"
#| label: results_preliminary_peroxidation
#
sum_m_peroxidation_prel <- m_prel_peroxidation %>%
  dplyr::select(starts_with("b_")) %>%  # Removes random effect terms
  summarise_draws() %>%
  mutate(across(where(is.numeric), ~ as.numeric(format_dec(.x, 3))))
#
flextable(sum_m_peroxidation_prel)
```

Model formula: peroxidation ~ cort * temp + age + sex + (1|clutch).
Model convergence was checked through rhat and ess_bulk values. Summary indicates no effect of sex, so it was discarded from the final models. However, we saw an effect of age and we included it in our final models.

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

Table S6. Preliminary results of the models testing for learning.
```{r, results_preliminary_learning}
#| tbl-cap: "Preliminary results of the models testing for lipid peroxidation"
#| label: results_preliminary_peroxidation
#
sum_m_learn_prel <- m_prel_learn %>%
  dplyr::select(starts_with("b_")) %>%  # Removes random effect terms
  summarise_draws() %>%
  mutate(across(where(is.numeric), ~ as.numeric(format_dec(.x, 3))))
#
flextable(sum_m_learn_prel)
```

Model formula: errors ~ day * cort * temp + sex + age+ (1 + day | lizard_id) + (1|clutch).
Model convergence was checked through rhat and ess_bulk values. **Summary indicates no effect of sex, so it was discarded from the final models. However, we saw an effect of age and we included it in our final models.**

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```





#### Final models diagnostics (plots)

```{r , plotmod_mitdensity, out.width="70%", fig.align="center"}
#| label: plotmod_mitdensity
#| caption: "Posterior predictive checks for the model of Mitochondrial Density in Olfactory Bulbs."
#
mod <- readRDS(here("output/models/mit_density_def.rds"))
plot_mod <- plot(mod, plot = FALSE)
#
plot_mod_1 <- plot_mod[[1]]
plot_mod_2 <- plot_mod[[2]]
#
fig_mod <- plot_grid(plot_mod_1, plot_mod_2, ncol = 1)
ggsave("./output/figures/suppl/Figure_SX3.png", plot = fig_mod,
       width = 20, height = 28, units = "cm", dpi = 600, bg = "white")
knitr::include_graphics("./output/figures/suppl/Figure_SX3.png")
```

Fig S1. Posterior predictive checks for the model of Mitochondrial Density in Olfactory Bulbs.
Formula: mean_mitodensity ~ cort * temp + (1|clutch)

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

```{r , plotmod_mitdensity_OT, out.width="70%", fig.align="center"}
#| label: plotmod_mitdensity_OT
#| caption: "Posterior predictive checks for the model of Mitochondrial Density in Optic Tecta."
#
mod <- readRDS(here("output/models/mean_mitodensity_def_OT.rds"))
plot_mod <- plot(mod, plot = FALSE)
#
plot_mod_1 <- plot_mod[[1]]
plot_mod_2 <- plot_mod[[2]]
#
fig_mod <- plot_grid(plot_mod_1, plot_mod_2, ncol = 1)
ggsave("./output/figures/suppl/Figure_SX4.png", plot = fig_mod,
       width = 20, height = 28, units = "cm", dpi = 600, bg = "white")
knitr::include_graphics("./output/figures/suppl/Figure_SX4.png")
```

Fig S2. Posterior predictive checks for the model of Mitochondrial Density in Optic Tecta.
Formula: mean_mitodensity ~ cort * temp + (1|clutch)

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

```{r , plotmod_potential_OB, out.width="70%", fig.align="center"}
#| label: plotmod_potential_OB
#| caption: "Posterior predictive checks for the model of Mitochondrial Potential in Olfactory Bulbs."
#
mod <- readRDS(here("output/models/mean_potential_def_OB.rds"))
plot_mod <- plot(mod, plot = FALSE)
#
plot_mod_1 <- plot_mod[[1]]
plot_mod_2 <- plot_mod[[2]]
#
fig_mod <- plot_grid(plot_mod_1, plot_mod_2, ncol = 1)
ggsave("./output/figures/suppl/Figure_SX5.png", plot = fig_mod,
       width = 20, height = 28, units = "cm", dpi = 600, bg = "white")
knitr::include_graphics("./output/figures/suppl/Figure_SX5.png")
```

Fig S3. Posterior predictive checks for the model of Mitochondrial Potential in Olfactory Bulbs.
Formula: mean_potential ~ cort * temp + (1|clutch)

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

```{r , plotmod_potential_OT, out.width="70%", fig.align="center"}
#| label: plotmod_potential_OT
#| caption: "Posterior predictive checks for the model of Mitochondrial Potential in Optic Tecta."
#
mod <- readRDS(here("output/models/mean_potential_def_OT.rds"))
plot_mod <- plot(mod, plot = FALSE)
#
plot_mod_1 <- plot_mod[[1]]
plot_mod_2 <- plot_mod[[2]]
#
fig_mod <- plot_grid(plot_mod_1, plot_mod_2, ncol = 1)
ggsave("./output/figures/suppl/Figure_SX6.png", plot = fig_mod,
       width = 20, height = 28, units = "cm", dpi = 600, bg = "white")
knitr::include_graphics("./output/figures/suppl/Figure_SX6.png")
```

Fig S4. Posterior predictive checks for the model of Mitochondrial Potential in Optic Tecta.
Formula: mean_potential ~ cort * temp + (1|clutch)

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

```{r , plotmod_ros_OB, out.width="70%", fig.align="center"}
#| label: plotmod_ros_OB
#| caption: "Posterior predictive checks for the model of ROS Production in Olfactory Bulbs."
#
mod <- readRDS(here("output/models/mean_ros_def_OB.rds"))
plot_mod <- plot(mod, plot = FALSE)
#
plot_mod_1 <- plot_mod[[1]]
plot_mod_2 <- plot_mod[[2]]
#
fig_mod <- plot_grid(plot_mod_1, plot_mod_2, ncol = 1)
ggsave("./output/figures/suppl/Figure_SX7.png", plot = fig_mod,
       width = 20, height = 28, units = "cm", dpi = 600, bg = "white")
knitr::include_graphics("./output/figures/suppl/Figure_SX7.png")
```

Fig S5. Posterior predictive checks for the model of ROS Production in Olfactory Bulbs.
Formula: mean_ros ~ cort * temp + (1|clutch)

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

```{r , plotmod_ros_OT, out.width="70%", fig.align="center"}
#| label: plotmod_ros_OT
#| caption: "Posterior predictive checks for the model of ROS Production in Optic Tecta."
#
mod <- readRDS(here("output/models/mean_ros_def_OT.rds"))
plot_mod <- plot(mod, plot = FALSE)
#
plot_mod_1 <- plot_mod[[1]]
plot_mod_2 <- plot_mod[[2]]
#
fig_mod <- plot_grid(plot_mod_1, plot_mod_2, ncol = 1)
ggsave("./output/figures/suppl/Figure_SX8.png", plot = fig_mod,
       width = 20, height = 28, units = "cm", dpi = 600, bg = "white")
knitr::include_graphics("./output/figures/suppl/Figure_SX8.png")
```

Fig S6. Posterior predictive checks for the model of ROS Production in Optic Tecta.
Formula: mean_ros ~ cort * temp + (1|clutch)

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

```{r , plotmod_dnadamage_OB, out.width="70%", fig.align="center"}
#| label: plotmod_dnadamage_OB
#| caption: "Posterior predictive checks for the model of DNA Damage in Olfactory Bulbs."
#
mod <- readRDS(here("output/models/mean_dnadamage_def_OB.rds"))
plot_mod <- plot(mod, plot = FALSE)
#
plot_mod_1 <- plot_mod[[1]]
plot_mod_2 <- plot_mod[[2]]
#
fig_mod <- plot_grid(plot_mod_1, plot_mod_2, ncol = 1)
ggsave("./output/figures/suppl/Figure_SX9.png", plot = fig_mod,
       width = 20, height = 28, units = "cm", dpi = 600, bg = "white")
knitr::include_graphics("./output/figures/suppl/Figure_SX9.png")
```

Fig S7. Posterior predictive checks for the model of DNA Damage in Olfactory Bulbs.
Formula: mean_dnadamage ~ cort * temp + age_euthanasia + sex + (1|clutch)

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

```{r , plotmod_dnadamage_OT, out.width="70%", fig.align="center"}
#| label: plotmod_dnadamage_OT
#| caption: "Posterior predictive checks for the model of DNA Damage in Optic Tecta."
#
mod <- readRDS(here("output/models/mean_dnadamage_def_OT.rds"))
plot_mod <- plot(mod, plot = FALSE)
#
plot_mod_1 <- plot_mod[[1]]
plot_mod_2 <- plot_mod[[2]]
#
fig_mod <- plot_grid(plot_mod_1, plot_mod_2, ncol = 1)
ggsave("./output/figures/suppl/Figure_SX10.png", plot = fig_mod,
       width = 20, height = 28, units = "cm", dpi = 600, bg = "white")
knitr::include_graphics("./output/figures/suppl/Figure_SX10.png")
```

Fig S8. Posterior predictive checks for the model of DNA Damage in Optic Tecta.
Formula: mean_dnadamage ~ cort * temp + sex + (1|clutch)

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

```{r , plotmod_peroxidation_OB, out.width="70%", fig.align="center"}
#| label: plotmod_peroxidation_OB
#| caption: "Posterior predictive checks for the model of Lipid Peroxidation in Olfactory Bulbs."
#
mod <- readRDS(here("output/models/mean_peroxidation_def_OB.rds"))
plot_mod <- plot(mod, plot = FALSE)
#
plot_mod_1 <- plot_mod[[1]]
plot_mod_2 <- plot_mod[[2]]
#
fig_mod <- plot_grid(plot_mod_1, plot_mod_2, ncol = 1)
ggsave("./output/figures/suppl/Figure_SX11.png", plot = fig_mod,
       width = 20, height = 28, units = "cm", dpi = 600, bg = "white")
knitr::include_graphics("./output/figures/suppl/Figure_SX11.png")
```

Fig S9. Posterior predictive checks for the model of Lipid Peroxidation in Olfactory Bulbs.
Formula: mean_peroxidation ~ cort * temp + age_euthanasia + (1|clutch)

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

```{r , plotmod_peroxidation_OT, out.width="70%", fig.align="center"}
#| label: plotmod_peroxidation_OT
#| caption: "Posterior predictive checks for the model of Lipid Peroxidation in Optic Tecta."
#
mod <- readRDS(here("output/models/mean_peroxidation_def_OT.rds"))
plot_mod <- plot(mod, plot = FALSE)
#
plot_mod_1 <- plot_mod[[1]]
plot_mod_2 <- plot_mod[[2]]
#
fig_mod <- plot_grid(plot_mod_1, plot_mod_2, ncol = 1)
ggsave("./output/figures/suppl/Figure_SX12.png", plot = fig_mod,
       width = 20, height = 28, units = "cm", dpi = 600, bg = "white")
knitr::include_graphics("./output/figures/suppl/Figure_SX12.png")
```

Fig S10. Posterior predictive checks for the model of Lipid Peroxidation in Optic Tecta.
Formula: mean_peroxidation ~ cort * temp + age_euthanasia + (1|clutch)

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

```{r , plotmod_tD_Chemical, out.width="70%", fig.align="center"}
#| label: plotmod_tD_Chemical
#| caption: "Posterior predictive checks for the model of Detection Latency (t_D) in Chemical trials."
#
mod <- readRDS(here("output/models/t_D_def_Chemical.rds"))
plot_mod <- plot(mod, plot = FALSE)
#
plot_mod_1 <- plot_mod[[1]]
plot_mod_2 <- plot_mod[[2]]
#
fig_mod <- plot_grid(plot_mod_1, plot_mod_2, ncol = 1)
ggsave("./output/figures/suppl/Figure_SX1.png", plot = fig_mod,
       width = 20, height = 28, units = "cm", dpi = 600, bg = "white")
knitr::include_graphics("./output/figures/suppl/Figure_SX1.png")
```

Fig S11. Posterior predictive checks for the model of Detection Latency (t_D) in Chemical trials.
Formula: t_D~ cort * temp + motivation + cort:motivation + (1|clutch) + (1|lizard_id)

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

```{r , plotmod_tD_Visual, out.width="70%", fig.align="center"}
#| label: plotmod_tD_Visual
#| caption: "Posterior predictive checks for the model of Detection Latency (t_D) in Visual trials."
#
mod <- readRDS(here("output/models/t_D_def_Visual.rds"))
plot_mod <- plot(mod, plot = FALSE)
#
plot_mod_1 <- plot_mod[[1]]
plot_mod_2 <- plot_mod[[2]]
#
fig_mod <- plot_grid(plot_mod_1, plot_mod_2, ncol = 1)
ggsave("./output/figures/suppl/Figure_SX2.png", plot = fig_mod,
       width = 20, height = 28, units = "cm", dpi = 600, bg = "white")
knitr::include_graphics("./output/figures/suppl/Figure_SX2.png")
```

Fig S12. Posterior predictive checks for the model of Detection Latency (t_D) in Visual trials.
Formula: t_D~ cort * temp + (1|clutch) + (1|lizard_id)

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```
